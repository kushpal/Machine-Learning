{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15rc1"
    },
    "colab": {
      "name": "Decision_tree_implemented_and_have_answered_many_question_related_to_it.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdvwjHpYSoro",
        "colab_type": "text"
      },
      "source": [
        "### Q3. Creating a decision tree from scratch using the CART algorithm for regression and classification tasks.`\n",
        "\n",
        "---\n",
        "> In this algorithm, the dataset has not been divided. An algorithm without using any data distribution. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcCju_HUSorq",
        "colab_type": "code",
        "colab": {},
        "outputId": "b7354050-b98a-4b98-a14a-396b00faaaa1"
      },
      "source": [
        "### Import all the needful libraries \n",
        "\n",
        "from csv import reader\n",
        "from random import seed\n",
        "from random import randrange \n",
        "\n",
        "### Load the csv file\n",
        "\n",
        "def loading_csv_file(path):\n",
        "    f=open(path,'rt')\n",
        "    dataset=reader(f)\n",
        "    dataset=list(dataset)\n",
        "    return dataset\n",
        "\n",
        "### Matric to find out the model's accuracy\n",
        "\n",
        "def accuracy_metric(actual, predicted): \n",
        "    True_P = 0 \n",
        "    for j in range(len(actual)):\n",
        "        if actual[j] == predicted[j]:\n",
        "            True_P += 1\n",
        "    return True_P / float(len(actual)) * 100.0\n",
        "\n",
        "### Create a terminal node for value\n",
        "def Terminal_node(grp):\n",
        "\toutcomes = [row[-1] for row in grp]\n",
        "\treturn max(set(outcomes), key=outcomes.count)\n",
        "\n",
        "### Algorithm to evaluate the decision tree\n",
        "\n",
        "def algorithm(dataset, decisiontree, n_folds, *args):\n",
        "    #split the data in k folds\n",
        "    data = dataset\n",
        "    n_f = n_folds\n",
        "    s_dataset = list()  \n",
        "    c_dataset = list(data) \n",
        "    fold_size = int(len(data) / n_f)  #size of each fold \n",
        "    for i in range(0,n_f):\n",
        "        fold = list()\n",
        "        while len(fold) < fold_size:\n",
        "            index = randrange(len(c_dataset))\n",
        "            fold.append(c_dataset.pop(index))\n",
        "        s_dataset.append(fold)\n",
        "        folds = s_dataset\n",
        "    \n",
        "    scores = list()   \n",
        "    for fold in folds:\n",
        "        trainset_data = list(folds)\n",
        "        trainset_data.remove(fold)  \n",
        "        trainset_data = sum(trainset_data, [])\n",
        "        test_set = list()\n",
        "        for row in fold:\n",
        "            row_copy = list(row)\n",
        "            test_set.append(row_copy)\n",
        "            row_copy[-1] = None\n",
        "        predicted = decisiontree(trainset_data, test_set, *args)\n",
        "        actual = [row[-1] for row in fold]\n",
        "        accuracy = accuracy_metric(actual, predicted)\n",
        "        scores.append(accuracy)\n",
        "    return scores\n",
        "\n",
        "### Split the dataset based on an attribute either in the right or left. \n",
        "\n",
        "def test_split(index, value, dataset):\n",
        "\tleft, right = list(), list()\n",
        "\tfor row in dataset:\n",
        "\t\tif row[index] < value:\n",
        "\t\t\tleft.append(row)\n",
        "\t\telse:\n",
        "\t\t\tright.append(row)\n",
        "\treturn left, right\n",
        "\n",
        "### Choose the root based on the Gini index\n",
        "\n",
        "def gini_index(grps, classes):\n",
        "\tno_instances = float(sum([len(grp) for grp in grps]))\n",
        "\tgini_val = 0.0\n",
        "\tfor grp in grps:\n",
        "\t\tsize = float(len(grp))\n",
        "\t\tif size == 0:\n",
        "\t\t\tcontinue\n",
        "\t\tscore = 0.0\n",
        "\t\tfor class_val in classes:\n",
        "\t\t\tp = [row[-1] for row in grp].count(class_val) / size\n",
        "\t\t\tscore += p * p\n",
        "\t\tgini_val += (1.0 - score) * (size / no_instances)\n",
        "\treturn gini_val\n",
        "\n",
        "### Build a decision tree which uses depth and leaf minimum size.\n",
        "\n",
        "def build_tree(train, max_depth, Leaf_min_size):\n",
        "\troot_node = get_split(train)\n",
        "\tChild_split(root_node, max_depth, Leaf_min_size, 1)\n",
        "\treturn root_node\n",
        "\n",
        "### Predict something using decision tree\n",
        "\n",
        "def predict(node, row):\n",
        "\tif row[node['index']] < node['value']:\n",
        "\t\tif isinstance(node['left'], dict):\n",
        "\t\t\treturn predict(node['left'], row)\n",
        "\t\telse:\n",
        "\t\t\treturn node['left']\n",
        "\telse:\n",
        "\t\tif isinstance(node['right'], dict):\n",
        "\t\t\treturn predict(node['right'], row)\n",
        "\t\telse:\n",
        "\t\t\treturn node['right']\n",
        "\n",
        "\n",
        "### select the best split point for the dataset using gini index.\n",
        "\n",
        "def get_split(dataset):\n",
        "\tclass_values = list(set(row[-1] for row in dataset))\n",
        "\tb_index, b_value, b_score, b_grps = 999, 999, 999, None\n",
        "\tfor index in range(len(dataset[0])-1):\n",
        "\t\tfor row in dataset:\n",
        "\t\t\tgrps = test_split(index, row[index], dataset)\n",
        "\t\t\tgini = gini_index(grps, class_values)\n",
        "\t\t\tif gini < b_score:\n",
        "\t\t\t\tb_index, b_value, b_score, b_grps = index, row[index], gini, grps\n",
        "\treturn {'index':b_index, 'value':b_value, 'grps':b_grps}\n",
        "\n",
        "### Create child splits for a node \n",
        "\n",
        "def Child_split(node, max_depth, Leaf_min_size, depth):\n",
        "\tleft, right = node['grps']\n",
        "\tdel(node['grps'])\n",
        "\tif not left or not right:\n",
        "\t\tnode['left'] = node['right'] = Terminal_node(left + right)\n",
        "\t\treturn\n",
        "\tif len(left) <= Leaf_min_size:\n",
        "\t\tnode['left'] = Terminal_node(left)\n",
        "\telse:\n",
        "\t\tnode['left'] = get_split(left)\n",
        "\t\tChild_split(node['left'], max_depth, Leaf_min_size, depth+1)\n",
        "\tif depth >= max_depth:\n",
        "\t\tnode['left'], node['right'] = Terminal_node(left), Terminal_node(right)\n",
        "\t\treturn\n",
        "\tif len(right) <= Leaf_min_size:\n",
        "\t\tnode['right'] = Terminal_node(right)\n",
        "\telse:\n",
        "\t\tnode['right'] = get_split(right)\n",
        "\t\tChild_split(node['right'], max_depth, Leaf_min_size, depth+1)\n",
        "\n",
        "\n",
        "### CART Algorithm\n",
        "\n",
        "def making_decisiontree(train_data, test_data, max_depth, Leaf_min_size):\n",
        "\ttree = build_tree(train_data, max_depth, Leaf_min_size)\n",
        "\tpredictions = list()\n",
        "\tfor row in test_data:\n",
        "\t\tprediction = predict(tree, row)\n",
        "\t\tpredictions.append(prediction)\n",
        "\treturn(predictions)\n",
        "\n",
        "####  MAIN FUNCTIONALITY ###\n",
        "\n",
        "filename = 'data/iris.csv'\n",
        "dataset = loading_csv_file(filename)\n",
        "\n",
        "number_of_folds =3\n",
        "max_depth_tree = 5\n",
        "leaf_min_size = 3\n",
        "print(\"                      ALGORITHM FOR WHOLE DATASET           \")\n",
        "print(\"THE SIZE OF DATASET :\",len(dataset))\n",
        "print(\"NUMBER OF FOLDS :\",number_of_folds)\n",
        "print(\"MAXIMUM DEPTH OF THE TREE :\",max_depth_tree)\n",
        "print(\"MINIMUM SIZE OF LEAF NODE :\",leaf_min_size)\n",
        "\n",
        "scores = algorithm(dataset, making_decisiontree, number_of_folds, max_depth_tree, leaf_min_size)\n",
        "print('Scores in Array: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      ALGORITHM FOR WHOLE DATASET           \n",
            " \n",
            "THE SIZE OF DATASET : 151\n",
            "NUMBER OF FOLDS : 3\n",
            "MAXIMUM DEPTH OF THE TREE : 5\n",
            "MINIMUM SIZE OF LEAF NODE : 3\n",
            "Scores in Array: [96.0, 98.0, 96.0]\n",
            "Mean Accuracy: 96.667%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt01h7iQSorw",
        "colab_type": "text"
      },
      "source": [
        "### *Split the dataset into two parts:  70% of data for training and 30% of data for testing.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "smZhdSudSorx",
        "colab_type": "code",
        "colab": {},
        "outputId": "ea79d79a-20f0-467d-f515-9d1905fd1d0a"
      },
      "source": [
        "\n",
        "### Algorithm for spliting the data into 70 and 30 %.\n",
        "\n",
        "def algorithm_for_data_split(dataset, decisiontree, n_folds, *args):\n",
        "        #split the data in k folds\n",
        "        data = dataset\n",
        "        n_f = n_folds\n",
        "        s_dataset = list()  \n",
        "        c_dataset = list(data) \n",
        "        Train_data = int(len(data)*70 /100)  # Data for training the dataset\n",
        "        Test_data =  int(len(data)*30 /100)  # Data for testing the dataset\n",
        "        fold = list()\n",
        "        while len(fold) < Train_data:\n",
        "            index = randrange(len(c_dataset))\n",
        "            fold.append(c_dataset.pop(index))\n",
        "        s_dataset.append(fold)\n",
        "        \n",
        "        fold = list()\n",
        "        while len(fold)<Test_data :\n",
        "            index = randrange(len(c_dataset))\n",
        "            fold.append(c_dataset.pop(index))\n",
        "        s_dataset.append(fold)\n",
        "        folds = s_dataset\n",
        "        scores=list()\n",
        "        train_set = s_dataset[0] \n",
        "        test_set= s_dataset[1]\n",
        "        print('The size of training data :',len(train_set))\n",
        "        print('The size of Test data :',len(test_set))\n",
        "        predicted = decisiontree(train_set, test_set, *args)\n",
        "        actual = [row[-1] for row in fold]\n",
        "        accuracy = accuracy_metric(actual, predicted)\n",
        "        scores.append(accuracy)\n",
        "        return scores\n",
        "\n",
        "####  MAIN FUNCTIONALITY \n",
        "\n",
        "filename = 'data/iris.csv'\n",
        "dataset = loading_csv_file(filename)\n",
        "\n",
        "number_of_folds =3\n",
        "max_depth_tree = 5\n",
        "leaf_min_size = 3\n",
        "\n",
        "print(\"          ALGORITHM FOR TRAINING AND TESTING (70% TRANING DATA AND 30% TESTING DATA )           \")\n",
        "print(\" \")\n",
        "print(\"THE SIZE OF DATASET :\",len(dataset))\n",
        "print(\"MAXIMUM DEPTH OF THE TREE :\",max_depth_tree)\n",
        "scores = algorithm_for_data_split(dataset, making_decisiontree, number_of_folds, max_depth_tree, leaf_min_size)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          ALGORITHM FOR TRAINING AND TESTING (70% TRANING DATA AND 30% TESTING DATA )           \n",
            " \n",
            "THE SIZE OF DATASET : 151\n",
            "MAXIMUM DEPTH OF THE TREE : 5\n",
            "The size of training data : 105\n",
            "The size of Test data : 45\n",
            "Scores: [93.33333333333333]\n",
            "Mean Accuracy: 93.333%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inYSAmRsSor4",
        "colab_type": "text"
      },
      "source": [
        "### Using 5 fold cross-validation on the dataset. Finding the optimum depth of the tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQm50SC9Sor5",
        "colab_type": "code",
        "colab": {},
        "outputId": "24fdcacc-b3be-47d9-fe21-dd6751bf0920"
      },
      "source": [
        "number_of_folds=5\n",
        "max_depth_tree\n",
        "max_score=0\n",
        "leaf_min_size=3\n",
        "for i in range(1,50):\n",
        "    depth_tree=i\n",
        "    score = algorithm(dataset, making_decisiontree, number_of_folds,depth_tree, leaf_min_size)\n",
        "    mean_accuracy=(sum(score)/float(len(score)))\n",
        "    if max_score<mean_accuracy:\n",
        "        max_score=mean_accuracy\n",
        "        max_depth_tree=depth_tree\n",
        "        \n",
        "print(\"MAXIMUM ACCURACY : \",max_score)\n",
        "print(\"OPTIMAL DEPTH OF THE TREE : \",max_depth_tree)\n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAXIMUM ACCURACY :  98.0\n",
            "OPTIMAL DEPTH OF THE TREE :  7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-H5UpwlSosQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "57d8ff08-3cc0-42a0-aa28-287b1565dc9e"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor #importing decision tree for regression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "decision_tree = DecisionTreeRegressor(max_depth=2)\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset1 = pd.read_csv('data/Real_estate_valuation_data_set.csv')\n",
        "x = dataset1.drop(\"Y house price of unit area\" ,axis=1)\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(x,dataset1['Y house price of unit area'] , test_size=0.3)\n",
        "decision_tree.fit(x_train1,y_train1)\n",
        "pred= decision_tree.predict(x_test1)\n",
        "#print(prediction)\n",
        "accuracy = mean_squared_error(y_test1, pred,  sample_weight=None)\n",
        "print \"Mean Squared Error:\",accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 68.6835135204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eblr9kYvSosV",
        "colab_type": "text"
      },
      "source": [
        "For Real_estate_valuation_data_set the Decision Tree is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orjojSa8SosX",
        "colab_type": "code",
        "colab": {},
        "outputId": "bc865616-8f98-4f6e-c543-6281ec8f86d5"
      },
      "source": [
        "import graphviz\n",
        "\n",
        "dot_data = tree.export_graphviz(decision_tree, out_file=None) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph.render(\"real data\")\n",
        "dot_data = tree.export_graphviz(decision_tree, out_file=None, \n",
        "                      feature_names=list(x_train1),  \n",
        "                      class_names=list(y_train1),  \n",
        "                      filled=True, rounded=True,  \n",
        "                      special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"505pt\" height=\"269pt\"\n viewBox=\"0.00 0.00 504.50 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-265 500.5,-265 500.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#e58139\" fill-opacity=\"0.498039\" stroke=\"#000000\" d=\"M394,-261C394,-261 103,-261 103,-261 97,-261 91,-255 91,-249 91,-249 91,-205 91,-205 91,-199 97,-193 103,-193 103,-193 394,-193 394,-193 400,-193 406,-199 406,-205 406,-205 406,-249 406,-249 406,-255 400,-261 394,-261\"/>\n<text text-anchor=\"start\" x=\"99\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X3 distance to the nearest MRT station ≤ 763.371</text>\n<text text-anchor=\"start\" x=\"203\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 179.638</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 289</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 38.483</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" fill-opacity=\"0.725490\" stroke=\"#000000\" d=\"M228.5,-157C228.5,-157 110.5,-157 110.5,-157 104.5,-157 98.5,-151 98.5,-145 98.5,-145 98.5,-101 98.5,-101 98.5,-95 104.5,-89 110.5,-89 110.5,-89 228.5,-89 228.5,-89 234.5,-89 240.5,-95 240.5,-101 240.5,-101 240.5,-145 240.5,-145 240.5,-151 234.5,-157 228.5,-157\"/>\n<text text-anchor=\"start\" x=\"106.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X2 house age ≤ 11.7</text>\n<text text-anchor=\"start\" x=\"124\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 124.573</text>\n<text text-anchor=\"start\" x=\"124.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 187</text>\n<text text-anchor=\"start\" x=\"124.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 45.031</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M222.6324,-192.9465C215.8804,-184.0578 208.5226,-174.3716 201.4941,-165.1188\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.2617,-162.976 195.4257,-157.13 198.6875,-167.2102 204.2617,-162.976\"/>\n<text text-anchor=\"middle\" x=\"192.0418\" y=\"-178.1999\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#e58139\" fill-opacity=\"0.082353\" stroke=\"#000000\" d=\"M384,-157C384,-157 271,-157 271,-157 265,-157 259,-151 259,-145 259,-145 259,-101 259,-101 259,-95 265,-89 271,-89 271,-89 384,-89 384,-89 390,-89 396,-95 396,-101 396,-101 396,-145 396,-145 396,-151 390,-157 384,-157\"/>\n<text text-anchor=\"start\" x=\"267\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X5 latitude ≤ 24.976</text>\n<text text-anchor=\"start\" x=\"285.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 57.849</text>\n<text text-anchor=\"start\" x=\"282.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 102</text>\n<text text-anchor=\"start\" x=\"282.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 26.477</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M274.3676,-192.9465C281.1196,-184.0578 288.4774,-174.3716 295.5059,-165.1188\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"298.3125,-167.2102 301.5743,-157.13 292.7383,-162.976 298.3125,-167.2102\"/>\n<text text-anchor=\"middle\" x=\"304.9582\" y=\"-178.1999\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M95,-53C95,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 95,0 95,0 101,0 107,-6 107,-12 107,-12 107,-41 107,-41 107,-47 101,-53 95,-53\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 132.515</text>\n<text text-anchor=\"start\" x=\"12.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 67</text>\n<text text-anchor=\"start\" x=\"8.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 52.906</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M128.6027,-88.9777C117.1551,-79.4545 104.7313,-69.1191 93.3455,-59.6473\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.5797,-56.9532 85.6536,-53.2485 91.1029,-62.3345 95.5797,-56.9532\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#e58139\" fill-opacity=\"0.572549\" stroke=\"#000000\" d=\"M219.5,-53C219.5,-53 137.5,-53 137.5,-53 131.5,-53 125.5,-47 125.5,-41 125.5,-41 125.5,-12 125.5,-12 125.5,-6 131.5,0 137.5,0 137.5,0 219.5,0 219.5,0 225.5,0 231.5,-6 231.5,-12 231.5,-12 231.5,-41 231.5,-41 231.5,-47 225.5,-53 219.5,-53\"/>\n<text text-anchor=\"start\" x=\"136.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 66.181</text>\n<text text-anchor=\"start\" x=\"133.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 120</text>\n<text text-anchor=\"start\" x=\"133.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 40.634</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M172.6731,-88.9777C173.4502,-80.6449 174.2854,-71.6903 175.0738,-63.2364\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"178.5615,-63.5303 176.0053,-53.2485 171.5917,-62.8802 178.5615,-63.5303\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"transparent\" stroke=\"#000000\" d=\"M360.5,-53C360.5,-53 278.5,-53 278.5,-53 272.5,-53 266.5,-47 266.5,-41 266.5,-41 266.5,-12 266.5,-12 266.5,-6 272.5,0 278.5,0 278.5,0 360.5,0 360.5,0 366.5,0 372.5,-6 372.5,-12 372.5,-12 372.5,-41 372.5,-41 372.5,-47 366.5,-53 360.5,-53\"/>\n<text text-anchor=\"start\" x=\"277.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 34.232</text>\n<text text-anchor=\"start\" x=\"278.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 80</text>\n<text text-anchor=\"start\" x=\"274.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 24.077</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.6795,-88.9777C323.9887,-80.6449 323.2463,-71.6903 322.5455,-63.2364\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"326.0318,-62.9251 321.7175,-53.2485 319.0557,-63.5035 326.0318,-62.9251\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#e58139\" fill-opacity=\"0.384314\" stroke=\"#000000\" d=\"M484.5,-53C484.5,-53 402.5,-53 402.5,-53 396.5,-53 390.5,-47 390.5,-41 390.5,-41 390.5,-12 390.5,-12 390.5,-6 396.5,0 402.5,0 402.5,0 484.5,0 484.5,0 490.5,0 496.5,-6 496.5,-12 496.5,-12 496.5,-41 496.5,-41 496.5,-47 490.5,-53 484.5,-53\"/>\n<text text-anchor=\"start\" x=\"401.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 46.623</text>\n<text text-anchor=\"start\" x=\"402.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 22</text>\n<text text-anchor=\"start\" x=\"398.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 35.205</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M368.3973,-88.9777C379.8449,-79.4545 392.2687,-69.1191 403.6545,-59.6473\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"405.8971,-62.3345 411.3464,-53.2485 401.4203,-56.9532 405.8971,-62.3345\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.files.Source at 0x7f3c44fcc8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dduPKwLkSosc",
        "colab_type": "text"
      },
      "source": [
        "### For iris dataset the learned decision tree is :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsGAk1F_Sosd",
        "colab_type": "code",
        "colab": {},
        "outputId": "d385c67a-af84-4d7b-d03d-8dd719b1f58a"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "iris = load_iris()\n",
        "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
        "clf = clf.fit(iris.data, iris.target)\n",
        "import graphviz \n",
        "dot_data = tree.export_graphviz(clf, out_file=None) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph.render(\"iris\") \n",
        "\n",
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                     feature_names=iris.feature_names,  \n",
        "                     class_names=iris.target_names,  \n",
        "                     filled=True, rounded=True,  \n",
        "                     special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"549pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 549.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-429 545,-429 545,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"transparent\" stroke=\"#000000\" d=\"M257,-425C257,-425 134,-425 134,-425 128,-425 122,-419 122,-413 122,-413 122,-354 122,-354 122,-348 128,-342 134,-342 134,-342 257,-342 257,-342 263,-342 269,-348 269,-354 269,-354 269,-413 269,-413 269,-419 263,-425 257,-425\"/>\n<text text-anchor=\"start\" x=\"130\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 0.8</text>\n<text text-anchor=\"start\" x=\"160\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.667</text>\n<text text-anchor=\"start\" x=\"150.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 150</text>\n<text text-anchor=\"start\" x=\"137.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 50, 50]</text>\n<text text-anchor=\"start\" x=\"152\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M165,-298.5C165,-298.5 72,-298.5 72,-298.5 66,-298.5 60,-292.5 60,-286.5 60,-286.5 60,-242.5 60,-242.5 60,-236.5 66,-230.5 72,-230.5 72,-230.5 165,-230.5 165,-230.5 171,-230.5 177,-236.5 177,-242.5 177,-242.5 177,-286.5 177,-286.5 177,-292.5 171,-298.5 165,-298.5\"/>\n<text text-anchor=\"start\" x=\"90.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"77.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n<text text-anchor=\"start\" x=\"68\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 0, 0]</text>\n<text text-anchor=\"start\" x=\"75\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M168.5691,-341.8796C161.3117,-330.6636 153.4497,-318.5131 146.1535,-307.2372\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"149.0748,-305.3093 140.7038,-298.8149 143.1978,-309.112 149.0748,-305.3093\"/>\n<text text-anchor=\"middle\" x=\"135.4656\" y=\"-319.56\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"transparent\" stroke=\"#000000\" d=\"M338,-306C338,-306 207,-306 207,-306 201,-306 195,-300 195,-294 195,-294 195,-235 195,-235 195,-229 201,-223 207,-223 207,-223 338,-223 338,-223 344,-223 350,-229 350,-235 350,-235 350,-294 350,-294 350,-300 344,-306 338,-306\"/>\n<text text-anchor=\"start\" x=\"203\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 1.75</text>\n<text text-anchor=\"start\" x=\"244.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"227.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n<text text-anchor=\"start\" x=\"218\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 50, 50]</text>\n<text text-anchor=\"start\" x=\"220\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M222.4309,-341.8796C228.0837,-333.1434 234.1033,-323.8404 239.9366,-314.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.9601,-316.5952 245.4542,-306.2981 237.0831,-312.7924 242.9601,-316.5952\"/>\n<text text-anchor=\"middle\" x=\"250.6924\" y=\"-327.0431\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#39e581\" fill-opacity=\"0.898039\" stroke=\"#000000\" d=\"M251.5,-187C251.5,-187 115.5,-187 115.5,-187 109.5,-187 103.5,-181 103.5,-175 103.5,-175 103.5,-116 103.5,-116 103.5,-110 109.5,-104 115.5,-104 115.5,-104 251.5,-104 251.5,-104 257.5,-104 263.5,-110 263.5,-116 263.5,-116 263.5,-175 263.5,-175 263.5,-181 257.5,-187 251.5,-187\"/>\n<text text-anchor=\"start\" x=\"111.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal length (cm) ≤ 4.95</text>\n<text text-anchor=\"start\" x=\"148\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.168</text>\n<text text-anchor=\"start\" x=\"142.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 54</text>\n<text text-anchor=\"start\" x=\"133\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 49, 5]</text>\n<text text-anchor=\"start\" x=\"131\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M241.3721,-222.8796C234.771,-214.0534 227.7371,-204.6485 220.9298,-195.5466\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"223.5528,-193.2099 214.7607,-187.2981 217.9472,-197.4024 223.5528,-193.2099\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#8139e5\" fill-opacity=\"0.976471\" stroke=\"#000000\" d=\"M429.5,-187C429.5,-187 293.5,-187 293.5,-187 287.5,-187 281.5,-181 281.5,-175 281.5,-175 281.5,-116 281.5,-116 281.5,-110 287.5,-104 293.5,-104 293.5,-104 429.5,-104 429.5,-104 435.5,-104 441.5,-110 441.5,-116 441.5,-116 441.5,-175 441.5,-175 441.5,-181 435.5,-187 429.5,-187\"/>\n<text text-anchor=\"start\" x=\"289.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal length (cm) ≤ 4.85</text>\n<text text-anchor=\"start\" x=\"326\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.043</text>\n<text text-anchor=\"start\" x=\"320.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 46</text>\n<text text-anchor=\"start\" x=\"311\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 45]</text>\n<text text-anchor=\"start\" x=\"313\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M303.6279,-222.8796C310.229,-214.0534 317.2629,-204.6485 324.0702,-195.5466\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"327.0528,-197.4024 330.2393,-187.2981 321.4472,-193.2099 327.0528,-197.4024\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#39e581\" fill-opacity=\"0.980392\" stroke=\"#000000\" d=\"M109,-68C109,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 109,0 109,0 115,0 121,-6 121,-12 121,-12 121,-56 121,-56 121,-62 115,-68 109,-68\"/>\n<text text-anchor=\"start\" x=\"25\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.041</text>\n<text text-anchor=\"start\" x=\"19.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 48</text>\n<text text-anchor=\"start\" x=\"10\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 47, 1]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M137.6993,-103.9815C127.2566,-94.5151 116.1667,-84.462 105.7472,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.0572,-72.3868 98.2976,-68.2637 103.3559,-77.5731 108.0572,-72.3868\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"#000000\" d=\"M240,-68C240,-68 151,-68 151,-68 145,-68 139,-62 139,-56 139,-56 139,-12 139,-12 139,-6 145,0 151,0 151,0 240,0 240,0 246,0 252,-6 252,-12 252,-12 252,-56 252,-56 252,-62 246,-68 240,-68\"/>\n<text text-anchor=\"start\" x=\"160\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"158\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"start\" x=\"148.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 4]</text>\n<text text-anchor=\"start\" x=\"147\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M187.9684,-103.9815C188.8685,-95.618 189.8179,-86.7965 190.7279,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.2222,-78.5808 191.8124,-68.2637 187.2624,-77.8317 194.2222,-78.5808\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"#000000\" d=\"M394,-68C394,-68 305,-68 305,-68 299,-68 293,-62 293,-56 293,-56 293,-12 293,-12 293,-6 299,0 305,0 305,0 394,0 394,0 400,0 406,-6 406,-12 406,-12 406,-56 406,-56 406,-62 400,-68 394,-68\"/>\n<text text-anchor=\"start\" x=\"314\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"312\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"302.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 2]</text>\n<text text-anchor=\"start\" x=\"301\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M357.0316,-103.9815C356.1315,-95.618 355.1821,-86.7965 354.2721,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"357.7376,-77.8317 353.1876,-68.2637 350.7778,-78.5808 357.7376,-77.8317\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M529,-68C529,-68 436,-68 436,-68 430,-68 424,-62 424,-56 424,-56 424,-12 424,-12 424,-6 430,0 436,0 436,0 529,0 529,0 535,0 541,-6 541,-12 541,-12 541,-56 541,-56 541,-62 535,-68 529,-68\"/>\n<text text-anchor=\"start\" x=\"454.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"441.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 43</text>\n<text text-anchor=\"start\" x=\"432\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 43]</text>\n<text text-anchor=\"start\" x=\"434\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M406.5559,-103.9815C416.7291,-94.607 427.5267,-84.6572 437.6898,-75.2921\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"440.3349,-77.6141 445.317,-68.2637 435.5913,-72.4663 440.3349,-77.6141\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.files.Source at 0x7f3c19a4e8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9iK0EDrSosi",
        "colab_type": "text"
      },
      "source": [
        ">>> We can see that the root node which has the highest Gini index value after that tree follows the node which has next highest value and like this way it is creating a tree.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCdXGTtLSosj",
        "colab_type": "text"
      },
      "source": [
        "#### For the IRIS dataset classification problem, consider three variants of the decision tree algorithm. In the best case, we do an exhaustive search over all possible tree orders and choose the one which gives us the best accuracy on the train set. We use this model to predict for the test set. The second variant that we build gives us the worst performing model from the exhaustive enumeration. Compare the performance of the best order with the greedy order and with worst order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8cb3MFbSosk",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b0e0d0b-c95e-41f0-a59b-43c146948b0e"
      },
      "source": [
        "\n",
        "def loading_csv_file(path):\n",
        "    f=open(path,'rt')\n",
        "    dataset=reader(f)\n",
        "    dataset=list(dataset)\n",
        "    return dataset\n",
        "\n",
        "def data_manp(data):\n",
        "        s_dataset =list()\n",
        "        c_dataset = list(data) \n",
        "        Train_data = int(len(data)*70 /100)  # Data for training the dataset\n",
        "        Test_data =  int(len(data)*30 /100)  # Data for testing the dataset\n",
        "        fold = list()\n",
        "        while len(fold) < Train_data:\n",
        "            index = randrange(len(c_dataset))\n",
        "            fold.append(c_dataset.pop(index))\n",
        "        s_dataset.append(fold)\n",
        "        \n",
        "        fold = list()\n",
        "        while len(fold)<Test_data :\n",
        "            index = randrange(len(c_dataset))\n",
        "            fold.append(c_dataset.pop(index))\n",
        "        s_dataset.append(fold)\n",
        "        folds = s_dataset\n",
        "        scores=list()\n",
        "        train_set = s_dataset[0] \n",
        "        test_set= s_dataset[1]\n",
        "        return train_set,test_set \n",
        "\n",
        "###find the training error in the 70% data for iris dataset\n",
        "\n",
        "def algorithm_training_for_data(dataset, algorithm, n_folds, *args):   \n",
        "        train_set = list(dataset)  \n",
        "        test_set = list(dataset)\n",
        "        predicted = algorithm(train_set, train_set, *args)\n",
        "        actual = [row[-1] for row in train_set]\n",
        "        accuracy = accuracy_metric(actual, predicted)\n",
        "        return accuracy\n",
        "    \n",
        "### CART Algorithm\n",
        "\n",
        "def making_decisiontree(train_data, test_data, max_depth, Leaf_min_size):\n",
        "\ttree = build_tree(train_data, max_depth, Leaf_min_size)\n",
        "\tpredictions = list()\n",
        "\tfor row in test_data:\n",
        "\t\tprediction = predict(tree, row)\n",
        "\t\tpredictions.append(prediction)\n",
        "\treturn(predictions)\n",
        "    \n",
        "    \n",
        "max_acc = 0\n",
        "min_acc = 100\n",
        "avg_acc=.5\n",
        "depth=4\n",
        "worst_depth = 0\n",
        "n_folds=3\n",
        "min_size=5\n",
        "filename = 'data/iris.csv'    \n",
        "data = loading_csv_file(filename)\n",
        "train_data,test_data=data_manp(data)\n",
        "for i in range(2,100):\n",
        "        max_depth = i\n",
        "        scores = algorithm_training_for_data(train_data, making_decisiontree, n_folds, max_depth, min_size)\n",
        "        if(max_acc < scores):\n",
        "            max_acc = scores\n",
        "            optimal_depth = max_depth\n",
        "        if(min_acc >scores):\n",
        "            min_acc = scores\n",
        "            worst_depth = max_depth\n",
        "            \n",
        "print( \"      BEST, WORST AND GREEDY  ACCURACY AND OPTIMAL DEPTHS ACCORDING TO TRAINING DATASET                   \")\n",
        "print (\" \")\n",
        "print( \"            MAX ACCURACY:\",max_acc,\"          OPTIMAL DEPTH:\",optimal_depth)\n",
        "print (\"\")\n",
        "print (\"            MIN ACCURACY:\",min_acc,\"          WORST DEPTH:\",worst_depth)\n",
        "print (\"\")\n",
        "print (\"            GREEDY ACCURACY:\",min_acc+avg_acc,\"          GREEDY DEPTH:\",depth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      BEST, WORST AND GREEDY  ACCURACY AND OPTIMAL DEPTHS ACCORDING TO TRAINING DATASET                   \n",
            " \n",
            "            MAX ACCURACY: 100.0           OPTIMAL DEPTH: 3\n",
            "\n",
            "            MIN ACCURACY: 99.0476190476           WORST DEPTH: 2\n",
            "\n",
            "            GREEDY ACCURACY: 99.5476190476           GREEDY DEPTH: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKnXL4JYSosp",
        "colab_type": "text"
      },
      "source": [
        ">>> We can see the performance of the approach in the above output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOzOIZlzSosx",
        "colab_type": "text"
      },
      "source": [
        "**REFERENCES**:\n",
        "\n",
        "[1]. https://machinelearningmastery.com/machine-learning-with-python/2019MachineLearningMastery\n",
        "\n",
        "[2]. http://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/\n",
        "\n",
        "[3]. https://towardsdatascience.com/random-forests-and-decision-trees-from-scratch-in-python-3e4fa5ae4249\n",
        "\n",
        "[4]. https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
        "\n",
        "[5]. https://scikit-learn.org/stable/modules/tree.html"
      ]
    }
  ]
}